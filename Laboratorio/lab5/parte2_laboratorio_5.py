# -*- coding: utf-8 -*-
"""Parte2_Laboratorio_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14dkAec7dxoDrWHvD6kxkIZQVafh8mv2D

#Pre procesamiento de datos

Importación de librerías
"""

import os
from PIL import Image
import numpy as np
from matplotlib import pyplot

"""Función para procesar una imagen y convertirla a un array 1D en escala de grises"""

def process_image(image_path, size=(50, 50)):  # Aquí ajustamos el tamaño a 50x50
    # Cargar la imagen
    img = Image.open(image_path)
    # Convertir a escala de grises
    img = img.convert('L')
    # Redimensionar la imagen
    img = img.resize(size)
    # Convertir a array de NumPy
    img_array = np.array(img)
    # Invierte los valores de los píxeles en la imagen, convirtiendo los tonos claros en oscuros y viceversa.
    img_array = -1 * (img_array - 255)
    # Aplanar el array 2D a 1D (por ejemplo, de [50, 50] a [2500])
    img_array = img_array.flatten()
    return img_array

"""Acceso a drive"""

from google.colab import drive
drive.mount("/content/drive")

"""###Procesamiento de imagenes a Matrices NumPy
Este código se utiliza para procesar y almacenar imágenes de un conjunto de datos que contiene imágenes de lenguaje de señas americano (ASL) en archivos de formato .jpg. Para cada letra del alfabeto (A a Z), las imágenes correspondientes se encuentran en diferentes directorios. El código procesa todas las imágenes de cada letra, las convierte en matrices NumPy y almacena cada conjunto de datos de imágenes por letra.
"""

#Define la ruta del directorio donde se almacenan las imágenes de la letra "A" en el conjunto de datos.
image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/A'
# Inicializa una lista vacía
dataset = []
# Itera sobre los archivos en el directorio image_dir.
for filename in os.listdir(image_dir):
    # Solo procesará los archivos que terminan con la extensión .jpg
    if filename.endswith('.jpg'):
        # Construye la ruta completa del archivo de imagen utilizando el nombre del archivo y la ruta del directorio.
        image_path = os.path.join(image_dir, filename)
        #  Llama a la función process_image para procesar la imagen y lo convierte en un array de los píxeles de la imagen.
        img_array = process_image(image_path)
        # Añade el array de la imagen procesada a la lista dataset
        dataset.append(img_array)

# Convierte la lista dataset en un array de NumPy y lo asigna a la variable
A = np.array(dataset)

#Repite este proceso con cada carpeta del data set, de a la A a la Z para luego asignar Y

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/B'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
B = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/C'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
C = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/D'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
D = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/E'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
E = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/F'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
F = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/G'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
G = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/H'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
H = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/I'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
I = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/J'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
J = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/K'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
K = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/L'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
L = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/M'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
M = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/N'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
N = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/O'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
O = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/P'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
P = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/Q'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
Q = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/R'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
R = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/S'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
S = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/T'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
T = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/U'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
U = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/V'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
V = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/W'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
W = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/X'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
X = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/Y'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
Y = np.array(dataset)

image_dir = '/content/drive/MyDrive/machine learning/datasets/ASL_Dataset/Train/Z'
# Procesar todas las imágenes del directorio
dataset = []
for filename in os.listdir(image_dir):
    if filename.endswith('.jpg'):
        image_path = os.path.join(image_dir, filename)
        img_array = process_image(image_path)
        dataset.append(img_array)

# Convertir lista a array de NumPy
Z = np.array(dataset)

"""Verificar los datos"""

print(A.shape)
print(Z.shape)

"""Este código asigna etiquetas numéricas a cada conjunto de datos de imágenes , correspondientes a las letras del alfabeto (A a Z). A cada imagen se le añade una columna adicional que contiene un número que representa la etiqueta de la letra. Luego, concatena la nueva columna con las imágenes en forma de arrays de NumPy."""

# Se genera un array con una columna de etiquetas (números de 0 a 25, donde 0 representa "A", 1 representa "B", y así sucesivamente).
# Se usa np.concatenate para añadir esta columna de etiquetas como la primera columna en cada array de imágenes.
A = np.concatenate([np.full((A.shape[0], 1), 0), A], axis=1)
B = np.concatenate([np.full((B.shape[0], 1), 1), B], axis=1)
C = np.concatenate([np.full((C.shape[0], 1), 2), C], axis=1)
D = np.concatenate([np.full((D.shape[0], 1), 3), D], axis=1)
E = np.concatenate([np.full((E.shape[0], 1), 4), E], axis=1)
F = np.concatenate([np.full((F.shape[0], 1), 5), F], axis=1)
G = np.concatenate([np.full((G.shape[0], 1), 6), G], axis=1)
H = np.concatenate([np.full((H.shape[0], 1), 7), H], axis=1)
I = np.concatenate([np.full((I.shape[0], 1), 8), I], axis=1)
J = np.concatenate([np.full((J.shape[0], 1), 9), J], axis=1)
K = np.concatenate([np.full((K.shape[0], 1), 10), K], axis=1)
L = np.concatenate([np.full((L.shape[0], 1), 11), L], axis=1)
M = np.concatenate([np.full((M.shape[0], 1), 12), M], axis=1)
N = np.concatenate([np.full((N.shape[0], 1), 13), N], axis=1)
O = np.concatenate([np.full((O.shape[0], 1), 14), O], axis=1)
P = np.concatenate([np.full((P.shape[0], 1), 15), P], axis=1)
Q = np.concatenate([np.full((Q.shape[0], 1), 16), Q], axis=1)
R = np.concatenate([np.full((R.shape[0], 1), 17), R], axis=1)
S = np.concatenate([np.full((S.shape[0], 1), 18), S], axis=1)
T = np.concatenate([np.full((T.shape[0], 1), 19), T], axis=1)
U = np.concatenate([np.full((U.shape[0], 1), 20), U], axis=1)
V = np.concatenate([np.full((V.shape[0], 1), 21), V], axis=1)
W = np.concatenate([np.full((W.shape[0], 1), 22), W], axis=1)
X = np.concatenate([np.full((X.shape[0], 1), 23), X], axis=1)
Y = np.concatenate([np.full((Y.shape[0], 1), 24), Y], axis=1)
Z = np.concatenate([np.full((Z.shape[0], 1), 25), Z], axis=1)

"""Este código combina los arrays de imágenes etiquetadas de cada letra del alfabeto (A a Z) en un único conjunto de datos (dataset). Utilizando np.vstack, el código apila verticalmente los arrays correspondientes a cada letra para formar un único array grande que contiene todas las imágenes de las 26 letras."""

# Inicializa el conjunto de datos con las imágenes de la letra "A" y muestra la forma inicial del array.
dataset = A
print(dataset.shape)
# Usa np.vstack para apilar verticalmente las imágenes de la letra "B", "C",
# y así sucesivamente, hasta la letra "Z". Esto añade los datos de cada letra al conjunto general dataset
dataset = np.vstack((dataset, B))
dataset = np.vstack((dataset, C))
dataset = np.vstack((dataset, D))
dataset = np.vstack((dataset, E))
dataset = np.vstack((dataset, F))
dataset = np.vstack((dataset, G))
dataset = np.vstack((dataset, H))
dataset = np.vstack((dataset, I))
dataset = np.vstack((dataset, J))
dataset = np.vstack((dataset, K))
dataset = np.vstack((dataset, L))
dataset = np.vstack((dataset, M))
dataset = np.vstack((dataset, N))
dataset = np.vstack((dataset, O))
dataset = np.vstack((dataset, P))
dataset = np.vstack((dataset, Q))
dataset = np.vstack((dataset, R))
dataset = np.vstack((dataset, S))
dataset = np.vstack((dataset, T))
dataset = np.vstack((dataset, U))
dataset = np.vstack((dataset, V))
dataset = np.vstack((dataset, W))
dataset = np.vstack((dataset, X))
dataset = np.vstack((dataset, Y))
dataset = np.vstack((dataset, Z))
print(dataset.shape)

"""Este código realiza las siguientes acciones sobre un conjunto de datos de imágenes procesadas de lenguaje de señas americano (ASL):

1. Muestra una parte de las etiquetas del conjunto de datos.

2. Mezcla aleatoriamente el conjunto de datos.

3. Guarda el conjunto en un archivo.

4. Divide el conjunto de datos en subconjuntos de entrenamiento y prueba, normalizando las imágenes y separando las etiquetas (target) de los datos de imagen.
"""

# Muestra las primeras 100 etiquetas (primera columna) del conjunto de datos antes de que se mezcle.
print(dataset[:100,0])
# Mezcla aleatoriamente las filas del conjunto de datos
np.random.shuffle(dataset)
# Crea el directorio (si no existe) para guardar el archivo y guarda el conjunto de datos mezclado en formato .npy
os.makedirs(os.path.dirname('/content/drive/MyDrive/machine learning/datasets/guardar/dataset.npy'), exist_ok=True)
np.save('/content/drive/MyDrive/machine learning/datasets/guardar/dataset.npy', dataset)
# Vuelve a mostrar las primeras 100 etiquetas después de mezclar el conjunto de datos
print(dataset[:100,0])
# ivide los datos de imagen en conjuntos de entrenamiento (X_train) y prueba (X_test)
X_train = dataset[:20000,1:]/255
X_test = dataset[20000:26000,1:]/255
# Se separan las etiquetas (primera columna) correspondientes a las imágenes para entrenamiento (y_train) y prueba (y_test)
y_train = dataset[:20000,0]
y_test = dataset[20000:26000,0]
# Muestra los tamaños de arrays para verificar que fueron bien distribuidos
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""#Semi-Supervisado
El aprendizaje semisupervisado es un enfoque en el que un modelo de machine learning se entrena utilizando una pequeña cantidad de datos etiquetados junto con una gran cantidad de datos no etiquetados. La idea es mejorar la capacidad del modelo para aprender características relevantes de los datos no etiquetados aprovechando la estructura que brinda la pequeña porción etiquetada. Este método se utiliza especialmente cuando obtener datos etiquetados es costoso o difícil, pero hay una abundancia de datos sin etiquetar.

Este código aplica el algoritmo de clustering K-Means para explorar la estructura en los datos de prueba no etiquetados (X_test). Utiliza el Silhouette Score, una métrica que evalúa la calidad de los clusters formados, para identificar el número óptimo de clusters (k). El código realiza múltiples ejecuciones del algoritmo K-Means variando el número de clusters, y luego selecciona el valor de k que maximiza el Silhouette Score. Finalmente, grafica la relación entre el número de clusters y el Silhouette Score para evaluar visualmente la calidad del agrupamiento.
"""

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler

# Los datos de prueba (X_test) se escalan usando el StandardScaler para estandarizarlos,
# lo que asegura que todas las características tengan una media de 0 y desviación estándar de 1.
scaler = StandardScaler()
data_scaled = scaler.fit_transform(X_test)

# Se define un rango de valores para k (número de clusters) que será probado en el modelo K-Means.
rango_k = range(245, 255)

# Lista para almacenar los silhouette scores
silhouette_scores = []

# Aplicar k-means y calcular el Silhouette Score para cada valor de k
for k in rango_k:
    # Para cada valor, se aplica el algoritmo K-Means con k clusters
    kmeans = KMeans(n_clusters=k, random_state=42)
    # Se generan las etiquetas de cluster para los datos escalados.
    etiquetas = kmeans.fit_predict(data_scaled)

    # Calcular el silhouette score
    score = silhouette_score(data_scaled, etiquetas)
    silhouette_scores.append(score)
    print(f'Para k={k}, Silhouette Score: {score}')

# Crear una gráfica de Silhouette Score vs número de clusters (k)
plt.figure(figsize=(8, 6))
plt.plot(list(rango_k), silhouette_scores, marker='o')
plt.title('Silhouette Score vs Número de Clusters (k)')
plt.xlabel('Número de Clusters (k)')
plt.ylabel('Silhouette Score')
plt.grid(True)
plt.show()

# Encontrar el k con el Silhouette Score más alto
k_optimo = rango_k[np.argmax(silhouette_scores)]
print(f'El número óptimo de clusters es {k_optimo} con un Silhouette Score de {max(silhouette_scores)}')

"""Implementa el algoritmo de K-Means con el número óptimo de clusters (k_optimo) que fue determinado previamente. El modelo K-Means se ajusta a los datos de entrenamiento (X_train), y la salida incluye la distancia de cada punto de los datos a los centroides de los clusters formados."""

# Se importa la clase KMeans desde la biblioteca scikit-learn
from sklearn.cluster import KMeans

k = k_optimo
# Se crea una instancia del modelo K-Means con el número de clusters (k)
# y se establece un valor de random_state para garantizar que los resultados sean reproducibles.
kmeans = KMeans(n_clusters=k, random_state=42)
# El método fit_transform ajusta el modelo K-Means a los datos de entrenamiento (X_train)
# y devuelve un arreglo con las distancias de cada punto de los datos a los centroides
# de los clusters a los que pertenecen. Esta salida (X_digits_dist) contiene las distancias
X_digits_dist = kmeans.fit_transform(X_train)
print(X_digits_dist)

"""Este código selecciona los puntos representativos de cada cluster resultante del algoritmo K-Means, utilizando las distancias mínimas de cada punto hacia los centroides de los clusters. Estos puntos representativos serán los más cercanos a los centroides de sus respectivos clusters."""

# Identifica el punto que está más cerca del centro de cada cluster. y guarda sus indices
idxs = np.argmin(X_digits_dist, axis=0)
# Usando los índices encontrados en idxs, se seleccionan los puntos correspondientes en los datos de entrenamiento (X_train)
X_representative_digits = X_train[idxs]

"""Este código visualiza los puntos representativos de cada cluster en un conjunto de imágenes, mostrando los ejemplos más cercanos a los centroides"""

import matplotlib.pyplot as plt
# Se crea una nueva figura para la visualización con un tamaño de 10x25 pulgadas
plt.figure(figsize=(10,25))
# Se itera sobre el conjunto de datos X_representative_digits, donde cada imagen representativa de un cluster es procesada. index
for index, X_representative_digit in enumerate(X_representative_digits):
  # Se crea una cuadrícula de 25 filas y 10 columnas para acomodar las imágenes. index+1 asegura que las imágenes se colocan en orden secuencial
  plt.subplot(25, 10, index+1)
  # Se visualiza la imagen representativa usando plt.imshow()
  plt.imshow(X_representative_digit.reshape(50,50), cmap="binary")
  # Se elimina el eje alrededor de cada imagen para que la cuadrícula esté limpia
  plt.axis('off')
# Finalmente, se muestra la visualización complet
plt.show()

"""Anotación de las etiquetas (Gracias a tener un data set con etiquetas directamente las asignamos)"""

y_representative_digits = y_train[idxs]

"""Entrenamiento basado en las imagenes representativas"""

# Commented out IPython magic to ensure Python compatibility.
# Se importa la clase LogisticRegression del módulo sklearn.linear_model. Esta clase se utiliza para implementar un modelo de regresión logística
from sklearn.linear_model import LogisticRegression
# Se crea una instancia del modelo de regresión logística llamado log_reg2 con los siguientes parámetros:
# multi_class="ovr": Especifica que se utilizará el enfoque "one-vs-rest" (OvR) para manejar problemas multiclase, donde se entrena un clasificador binario para cada clase.
# solver="lbfgs": Indica el algoritmo de optimización a utilizar; lbfgs es un método eficiente para la optimización en problemas de regresión logística.
# max_iter=5000: Establece el número máximo de iteraciones para el algoritmo de optimización, permitiendo que el modelo tenga más tiempo para converger.
# random_state=42: Fija la semilla del generador de números aleatorios para garantizar la reproducibilidad de los resultados.
log_reg2 = LogisticRegression(multi_class="ovr", solver="lbfgs", max_iter=5000, random_state=42)
# Se entrena el modelo log_reg2 utilizando el método fit(), pasando las imágenes representativas
# (X_representative_digits) y sus etiquetas correspondientes (y_representative_digits)
# %time log_reg2.fit(X_representative_digits, y_representative_digits)
# Se evalúa el rendimiento del modelo entrenado utilizando el método score(),
# que calcula la precisión del modelo en el conjunto de prueba (X_test, y_test).
# Devuelve un valor entre 0 y 1 que representa la proporción de predicciones correctas realizadas por el modelo sobre el conjunto de prueba.
log_reg2.score(X_test, y_test)

"""Se hace el mismo entrenamiento con valores aleatorios para verificar que los valores representativos son más eficientes"""

# Commented out IPython magic to ensure Python compatibility.
log_reg = LogisticRegression(multi_class="ovr", solver="lbfgs", max_iter=5000, random_state=42)
# %time log_reg.fit(X_train[:50], y_train[:50])
log_reg.score(X_test, y_test)

# Se crea un array vacío llamado y_train_propagated con la misma longitud que X_train
y_train_propagated = np.empty(len(X_train))
# : Este bucle itera sobre cada cluster (del 0 al k-1 donde k es el nro optimo
for i in range(k):
  # Asigna la etiqueta correspondiente de las imágenes representativas (y_representative_digits[i]) a todas las imágenes en X_train que están en el cluster
  y_train_propagated[kmeans.labels_==i] = y_representative_digits[i]
print(y_train_propagated)

# Commented out IPython magic to ensure Python compatibility.
log_reg3 = LogisticRegression(multi_class="ovr", solver="lbfgs", max_iter=5000, random_state=42)
# %time log_reg3.fit(X_train[:1000], y_train_propagated[:1000])
# : Se evalúa el rendimiento del modelo entrenado (log_reg3) usando el método score(),
# que calcula la precisión del modelo en el conjunto de prueba (X_test, y_test).
log_reg3.score(X_test, y_test)

"""#Aprendizaje Activo
El aprendizaje activo es una técnica dentro del aprendizaje automático donde el modelo tiene la capacidad de seleccionar las muestras de entrenamiento más informativas. A diferencia de los enfoques tradicionales que utilizan un conjunto de datos estático, en el aprendizaje activo el modelo puede identificar qué ejemplos son más útiles para mejorar su rendimiento
"""

# Se utiliza el modelo log_reg3 para predecir las probabilidades de pertenencia a cada clase para las primeras 1000 imágenes de X_train
probas = log_reg3.predict_proba(X_train[:1000])
#  Se obtiene el índice de la clase con la probabilidad más alta para cada muestra en probas. np.argmax(probas, axis=1)
# devuelve un array con los índices de las clases predichas para cada una de las 1000 imágenes
labels_ixs = np.argmax(probas, axis=1)
# Se crea un array labels que contiene las probabilidades predichas para las clases asignadas a cada muestra. Utilizando una comprensión de listas
labels = np.array([proba[ix] for proba, ix in zip(probas, labels_ixs)])
#  Se ordenan los índices de labels en orden ascendente, produciendo un array sorted_ixs que contiene los índices de las probabilidades
sorted_ixs = np.argsort(labels)
# Finalmente, se seleccionan las 10 probabilidades más bajas utilizando sorted_ixs[:10],
# lo que permite identificar las 10 muestras que el modelo considera menos seguras
labels[sorted_ixs[:10]]

"""Visualización de las Muestras con Menor Confianza en las Predicciones: Este bloque de código se encarga de seleccionar y visualizar las imágenes que el modelo clasificador ha etiquetado con la menor probabilidad de confianza."""

# Aquí se seleccionan las imágenes del conjunto de entrenamiento (X_train[:1000]) que corresponden a las probabilidades más bajas calculadas previamente
X_lowest = X_train[:1000][sorted_ixs[:k]]
# Se crea una nueva figura para la visualización con un tamaño específico de 10 unidades de ancho y 25 unidades de alto
plt.figure(figsize=(10, 25))
# ste bucle itera sobre las imágenes en X_lowest. Para cada imagen (img), se crea un subplot en la figura que se ha preparado.
for index, img in enumerate(X_lowest):
    plt.subplot(25, 10, index + 1)
    plt.imshow(img.reshape(50, 50), cmap="binary", interpolation="bilinear")
    plt.axis('off')
plt.show()

"""Este fragmento de código se utiliza para extraer las etiquetas correspondientes a las muestras del conjunto de entrenamiento"""

# En esta línea, se seleccionan las etiquetas (y_train) correspondientes a las muestras que han sido identificadas como las menos confiables en la clasificación.
y_lowest = y_train[:1000][sorted_ixs[:k]]
# y_lowest contendrá las etiquetas de las imágenes en X_lowest, que son las que el modelo clasificó con menor confianza
y_lowest

"""El objetivo de este código es mejorar la calidad de las etiquetas en el conjunto de entrenamiento, asegurando que las muestras con menor confianza estén correctamente etiquetadas"""

# crea una copia de las primeras 1000 etiquetas del conjunto de entrenamiento propagado
y_train2 = y_train_propagated[:1000].copy()
# se reemplazan las etiquetas en y_train2 que corresponden a las k
# muestras con menor confianza (identificadas por los índices en sorted_ixs) con las etiquetas almacenadas en y_lowest
y_train2[sorted_ixs[:k]] = y_lowest

"""Se centra en el reentrenamiento de un modelo de regresión logística utilizando un conjunto de datos de entrenamiento con etiquetas actualizadas

Entrena un modelo de regresión logística utilizando un subconjunto del conjunto de entrenamiento (X_train[:1000]) y un conjunto de etiquetas mejorado (y_train2)

El objetivo es evaluar la efectividad del modelo al adaptarse a las etiquetas más precisas y representativas obtenidas a través de un proceso de aprendizaje activo.
"""

# Commented out IPython magic to ensure Python compatibility.
#Aquí se crea una instancia del modelo de regresión logística.
log_reg5 = LogisticRegression(multi_class="ovr", solver="lbfgs", max_iter=5000, random_state=42)
# %time log_reg5.fit(X_train[:1000], y_train2)
# Se evalúa la precisión del modelo entrenado utilizando el conjunto de prueba (X_test) y sus respectivas etiquetas (y_test)
log_reg5.score(X_test, y_test)